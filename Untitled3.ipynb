{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = sqlContext.read.load(\"Pawn.txt\", \n",
    "                      format='com.databricks.spark.csv', \n",
    "                      header='true', delimiter='\\t',mode='PERMISSIVE',\n",
    "                     inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store1=df1.where(df1.StoreName =='World Wide Gold Buyers and Silver LLC ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pawn_rdd=sc.textFile(\"Pawn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows_rdd1=pawn_rdd.zipWithIndex().toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#from stemming.porter2 import stem\n",
    "def clean_word(w):\n",
    "    w=str(w)\n",
    "    #w=re.sub('\\t\\t', '\\t', w)\n",
    "    w=re.sub('\\t\\t\\t+', '', w)\n",
    "    \n",
    "    return w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=rows_rdd1.rdd.map(lambda x: (clean_word(x[0]),x[1])).toDF().withColumnRenamed(\"_1\",\"doc_text\").withColumnRenamed(\"_2\",\"doc_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, size\n",
    "d1=text.filter(col(\"doc_id\")==152648)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows_rdd=text.rdd.map(lambda x:(x[0].split('\\t'),x[1])).toDF().withColumnRenamed(\"_1\",\"doc_text\").withColumnRenamed(\"_2\",\"doc_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, size\n",
    "rows_df1=rows_rdd.where(size(col(\"doc_text\"))==26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows_df2=rows_rdd.where(size(col(\"doc_text\"))==27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows_26=rows_df1.rdd.map(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows_27=rows_df2.rdd.map(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['World Wide Gold Buyers and Silver LLC ',\n",
       "  ' 415 Route 9 South ',\n",
       "  'Englishtown',\n",
       "  '',\n",
       "  'NJ',\n",
       "  '7726',\n",
       "  '732-490-5500',\n",
       "  '02/03/2016 14:10',\n",
       "  '50',\n",
       "  'Bucchere',\n",
       "  'Alexa',\n",
       "  'NULL',\n",
       "  '25/04/1991 0:00',\n",
       "  'NULL',\n",
       "  '',\n",
       "  'MARLBORO',\n",
       "  'NJ',\n",
       "  '7726',\n",
       "  '7327575751',\n",
       "  'NULL',\n",
       "  'NULL',\n",
       "  \"Ladies' 14K Yellow Gold Broach --- Other ---  Weight: 8.9dwt\",\n",
       "  'NULL',\n",
       "  'NULL',\n",
       "  'NULL',\n",
       "  'NULL',\n",
       "  '50']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_27.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header=rows_26.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head_rdd=sc.parallelize(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StoreName']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header1=head_rdd.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head1=header1.filter(lambda x:x[1]<=2).map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head2=header1.filter(lambda x:x[1]>2).map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=sc.parallelize(['Null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Null']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = head1.union(test).union(head2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4=rows_27.toDF(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5=df4.drop(df4.Null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pawn=df5.rdd.map(lambda x:x.Description)\n",
    "pawn_all=df5.rdd.map(lambda x:x).zipWithIndex().toDF()\n",
    "pawn_doc=df5.rdd.map(lambda x:x.Description).zipWithIndex().toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#from stemming.porter2 import stem\n",
    "def clean_word(w):\n",
    "    w=w.lower().strip()\n",
    "    w=re.sub('\\n',\" \",w)\n",
    "    #w=re.sub(r'\\s+', ' ', w).strip()\n",
    "    w=re.sub(\"[^a-z| |0-9]|,\\,|\\.|\\;|\\:|\\;|\\?|\\!|\\[|\\]|\\}|\\{(?i)\\b|[0-9]|((?:https?://|www\\d{0,3}))|[//]|[#]|[$]|\", \"\", (w.lower()))\n",
    "    w=re.sub('\\s\\s+', ' ', w)\n",
    "    return w.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=pawn_doc.rdd.map(lambda x: (clean_word(x[0]),x[1])).toDF().withColumnRenamed(\"_1\",\"doc_text\").withColumnRenamed(\"_2\",\"doc_id\")\n",
    "df = (text\n",
    "      .rdd\n",
    "  .map(lambda x : (x.doc_id, x.doc_text.split(\" \")))\n",
    "  .toDF()\n",
    "  .withColumnRenamed(\"_1\",\"doc_id\")\n",
    "  .withColumnRenamed(\"_2\",\"features\"))\n",
    "  \n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover = StopWordsRemover(inputCol=\"features\", outputCol=\"tags\")\n",
    "df0=remover.transform(df)\n",
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.sql.types import DoubleType\n",
    "htf = HashingTF(inputCol=\"tags\", outputCol=\"tf\")\n",
    "tf = htf.transform(df0)\n",
    "tf1=tf.select(\"doc_id\",\"tags\")\n",
    "pawn_rest=pawn_all.rdd.map(lambda x: (x[0],x[1])).toDF().withColumnRenamed(\"_1\",\"Pawn\").withColumnRenamed(\"_2\",\"doc_id\")\n",
    "in_df=pawn_rest.join(tf1,[\"doc_id\"]).drop(\"doc_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_df.coalesce(1).write.format('json').save('pawn_tags2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pawn=df3.rdd.map(lambda x:x.Description)\n",
    "pawn_all=df3.rdd.map(lambda x:x).zipWithIndex().toDF()\n",
    "pawn_doc=df3.rdd.map(lambda x:x.Description).zipWithIndex().toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#from stemming.porter2 import stem\n",
    "def clean_word(w):\n",
    "    w=w.lower().strip()\n",
    "    w=re.sub('\\n',\" \",w)\n",
    "    #w=re.sub(r'\\s+', ' ', w).strip()\n",
    "    w=re.sub(\"[^a-z| |0-9]|,\\,|\\.|\\;|\\:|\\;|\\?|\\!|\\[|\\]|\\}|\\{(?i)\\b|[0-9]|((?:https?://|www\\d{0,3}))|[//]|[#]|[$]|\", \"\", (w.lower()))\n",
    "    w=re.sub('\\s\\s+', ' ', w)\n",
    "    return w.lower().strip()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1=pawn_doc.rdd.map(lambda x: (clean_word(x[0]),x[1])).toDF().withColumnRenamed(\"_1\",\"doc_text\").withColumnRenamed(\"_2\",\"doc_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = (text1\n",
    "      .rdd\n",
    "  .map(lambda x : (x.doc_id, x.doc_text.split(\" \")))\n",
    "  .toDF()\n",
    "  .withColumnRenamed(\"_1\",\"doc_id\")\n",
    "  .withColumnRenamed(\"_2\",\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover = StopWordsRemover(inputCol=\"features\", outputCol=\"tags\")\n",
    "df0=remover.transform(df)\n",
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.sql.types import DoubleType\n",
    "htf = HashingTF(inputCol=\"tags\", outputCol=\"tf\")\n",
    "tf = htf.transform(df0)\n",
    "tf1=tf.select(\"doc_id\",\"tags\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pawn_rest=pawn_all.rdd.map(lambda x: (x[0],x[1])).toDF().withColumnRenamed(\"_1\",\"Pawn\").withColumnRenamed(\"_2\",\"doc_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_df=pawn_rest.join(tf1,[\"doc_id\"]).drop(\"doc_id\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
